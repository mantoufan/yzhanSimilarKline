# ğŸ“ˆ A è‚¡æ•°æ®æ™ºèƒ½åˆ†æç³»ç»Ÿ

## ğŸ“‘ ç›®å½•

1. [ä½œè€…ä¿¡æ¯](#-ä½œè€…ä¿¡æ¯)
2. [ç³»ç»Ÿç®€ä»‹](#-ç³»ç»Ÿç®€ä»‹)
3. [æºç åœ°å€](#-æºç åœ°å€)
4. [Demo æ¼”ç¤º](#-demo)
5. [è‡´è°¢](#-è‡´è°¢)
6. [æ­¥éª¤æ¼”ç¤º](#-æ­¥éª¤æ¼”ç¤º)
7. [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
   - [å®‰è£…æ­¥éª¤](#-å®‰è£…æ­¥éª¤)
   - [ä½¿ç”¨è¯´æ˜](#-ä½¿ç”¨è¯´æ˜)
   - [ä½¿ç”¨æç¤º](#-ä½¿ç”¨æç¤º)
8. [ç³»ç»Ÿæ¶æ„](#-ç³»ç»Ÿæ¶æ„)
9. [æ ¸å¿ƒæŠ€æœ¯å®ç°](#-æ ¸å¿ƒæŠ€æœ¯å®ç°)
   - [K çº¿å½¢æ€è¯†åˆ«ä¸ç›¸ä¼¼åº¦åŒ¹é…](#1-k-çº¿å½¢æ€è¯†åˆ«ä¸ç›¸ä¼¼åº¦åŒ¹é…)
   - [å¸‚åœºæ”¶ç›Šé¢„æµ‹](#2-å¸‚åœºæ”¶ç›Šé¢„æµ‹)
   - [æ™ºèƒ½é—®ç­”ç³»ç»Ÿ](#3-æ™ºèƒ½é—®ç­”ç³»ç»Ÿ)
   - [æ•°æ®å¤„ç†ä¼˜åŒ–](#4-æ•°æ®å¤„ç†ä¼˜åŒ–)
   - [æ€§èƒ½ä¼˜åŒ–ä¸ç¼“å­˜æœºåˆ¶](#5-æ€§èƒ½ä¼˜åŒ–ä¸ç¼“å­˜æœºåˆ¶)
10. [ç³»ç»Ÿç‰¹ç‚¹](#-ç³»ç»Ÿç‰¹ç‚¹)
11. [æ³¨æ„äº‹é¡¹](#-æ³¨æ„äº‹é¡¹)
12. [æ€»ç»“ä¸å±•æœ›](#-æ€»ç»“ä¸å±•æœ›)

## ğŸ‘¨â€ğŸ’» ä½œè€…ä¿¡æ¯

è¯¾ç¨‹ï¼šå•†ä¸šæ™ºèƒ½æŠ€æœ¯ã€€è€å¸ˆï¼šé˜®å…‰å†Œæ•™æˆ  
å§“åï¼šå´å°å®‡ã€€å­¦å·ï¼š71265700016 ã€€[é¡¹ç›®æ¼”ç¤º](http://a.os120.com)ã€€[æºç å’Œè¯´æ˜](https://github.com/mantoufan/yzhanSimilarKline)

## ğŸŒŸ ç³»ç»Ÿç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªé¢å‘æŠ•èµ„è€…çš„ A è‚¡å¸‚åœºæ™ºèƒ½åˆ†æç³»ç»Ÿï¼Œæ—¨åœ¨æä¾›å®¢è§‚çš„å¸‚åœºåˆ†æå’ŒæŠ•èµ„å»ºè®®ã€‚ğŸ’¡ å®ƒçš„æ ¸å¿ƒåœ¨äºå°†ä¼ ç»Ÿçš„æŠ€æœ¯åˆ†æå’Œç°ä»£äººå·¥æ™ºèƒ½ç›¸ç»“åˆï¼Œä¸ºå¸‚åœºå†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚

è¿™ä¸ªç³»ç»Ÿæ•´åˆäº†æŠ€æœ¯åˆ†æ ğŸ” å’Œæ™ºèƒ½é—®ç­” ğŸ’¬ åŠŸèƒ½ï¼Œé‡‡ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°å’Œæ¬§æ°è·ç¦»ç­‰ç®—æ³•è¿›è¡Œç›¸ä¼¼ K çº¿å½¢æ€è¯†åˆ«ï¼Œç»“åˆåŸºäºç»Ÿè®¡æ¦‚ç‡çš„ä»·æ ¼èµ°åŠ¿é¢„æµ‹ ğŸ“‰ï¼Œä»¥åŠé€šè¿‡å†å²ç›¸ä¼¼åº¦åŒ¹é…å’Œé£é™©åº¦é‡ï¼ˆæ ‡å‡†å·®/æ³¢åŠ¨ç‡ï¼‰çš„æŒä»“æœŸåˆ†æ ğŸ“Šï¼Œå¹¶åŸºäºå¸‚åœºå®æ—¶æ•°æ®ã€RAG æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œ GPT-4o-mini çš„æ™ºèƒ½é—®ç­”æœåŠ¡ã€‚

ç³»ç»Ÿé‡‡ç”¨ TF-IDF å‘é‡åŒ–ã€SVD é™ç»´ç­‰æœºå™¨å­¦ä¹ ç®—æ³•å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ ğŸ¤–ï¼Œè‡´åŠ›äºé€šè¿‡æ•°æ®é©±åŠ¨çš„æ–¹å¼ä¸ºæŠ•èµ„å†³ç­–æä¾›å‚è€ƒã€‚ç³»ç»Ÿè®¾è®¡çš„ç›®æ ‡æ˜¯å¸®åŠ©æŠ•èµ„è€…æ›´å…¨é¢åœ°äº†è§£å¸‚åœºä¿¡æ¯ï¼Œç†æ€§æƒè¡¡æŠ•èµ„é£é™©ã€‚âš–ï¸

## ğŸ”— æºç åœ°å€

[GitHub ä»“åº“](https://github.com/mantoufan/yzhanSimilarKline)

## ğŸ¥ Demo

åœ¨çº¿ä½¿ç”¨ï¼š[é˜¿é‡Œäº‘èŠ‚ç‚¹ï¼ˆæ¨èï¼Œé«˜é€Ÿï¼‰](https://a.os120.com/)ã€€[è°·æ­Œäº‘èŠ‚ç‚¹ï¼ˆæ…¢ï¼‰](https://skline.streamlit.app/)  
è§†é¢‘æ¼”ç¤ºï¼š[ç‚¹å‡»æ’­æ”¾](https://drfs.ctcontents.com/file/3312/1449317425/0a8f12/yun/business-ai-video-v2.mp4)  
åŠ¨ç”»æ¼”ç¤ºï¼ˆ[ä¸åŠ¨ç‚¹è¿™é‡Œ](https://github.com/user-attachments/assets/50e9544a-aafa-4a3b-ad3f-8b71cc1cd79e)ï¼‰
![business-ai-video-v2](https://github.com/user-attachments/assets/50e9544a-aafa-4a3b-ad3f-8b71cc1cd79e)

## ğŸ™ è‡´è°¢

ç‰¹åˆ«æ„Ÿè°¢é˜®å…‰å†Œæ•™æˆåœ¨å•†ä¸šæ™ºèƒ½æŠ€æœ¯è¯¾ç¨‹ä¸­å¯¹ç›¸å…³æŠ€æœ¯å’Œæ¡ˆä¾‹çš„è®²è§£ï¼Œå—ç›ŠåŒªæµ…ã€‚æ•™æˆçš„æŒ‡å¯¼å¸®åŠ©æˆ‘æ›´æ·±å…¥åœ°ç†è§£äº†å•†ä¸šæ™ºèƒ½æŠ€æœ¯çš„å®é™…åº”ç”¨ï¼Œä¸ºæœ¬é¡¹ç›®çš„å¼€å‘æä¾›äº†å®è´µçš„ç†è®ºä¾æ®å’Œæ€è·¯æ–¹å‘ã€‚ğŸ‘¨â€ğŸ«

## ğŸ“· æ­¥éª¤æ¼”ç¤º

æ­¥éª¤ 1ï¼šæœç´¢ å¹³å®‰ / ä¸Šè¯æŒ‡æ•° å…³é”®è¯ï¼Œå…¶å®ƒå…³é”®è¯æ²¡æœ‰ç¼“å­˜å¯èƒ½è¦ç­‰ 5 åˆ†é’Ÿ  
![æœç´¢ç•Œé¢](https://s2.loli.net/2025/01/20/GLUNQcoKB1yTM4p.png)

æ­¥éª¤ 2ï¼šä¸‹æ‹‰æŸ¥çœ‹å†å²ç›¸ä¼¼ K çº¿å›¾  
![Kçº¿åˆ†æ](https://s2.loli.net/2025/01/20/LprhMDcY7HvoqkA.png)

æ­¥éª¤ 3ï¼šåŸºäºæœ€ç›¸ä¼¼çš„ 10 æ¡å†å² K çº¿ï¼Œé¢„æµ‹æœªæ¥ 7 ä¸ªäº¤æ˜“æ—¥çš„æ¶¨è·Œæƒ…å†µ  
![è¶‹åŠ¿é¢„æµ‹](https://s2.loli.net/2025/01/20/PROF6TxjEzoQtqw.png)

æ­¥éª¤ 4ï¼šå¦‚æœå½“å‰äº¤æ˜“æ—¥ï¼ˆéäº¤æ˜“æ—¥æœ€è¿‘ï¼‰ï¼ŒæŒæœ‰ 1 - 7 äº¤æ˜“æ—¥çš„æ”¶ç›Šç‡å’Œèƒœç‡  
![æ”¶ç›Šåˆ†æ](https://s2.loli.net/2025/01/20/akrZ4QdLlyoSKIi.png)

æ­¥éª¤ 5ï¼šæ®ç”¨æˆ·è¾“å…¥é—®é¢˜ï¼ŒæŸ¥è¯¢æœ€ç›¸ä¼¼çš„ï¼Œå°†ç»“æ„åŒ–æ•°æ®è¯­ä¹‰åŒ–çš„ä¸åŒç±»å‹çš„æ•°æ®å—ï¼ŒåµŒå…¥æç¤ºè¯  
![æ•°æ®æ£€ç´¢](https://s2.loli.net/2025/01/20/XR9diAVMw2SZOlo.png)

æ­¥éª¤ 6ï¼šæ ¹æ®å†…ç½® + é—®é¢˜ + åµŒå…¥æ•°æ®å—çš„æç¤ºè¯å‘ç»™ GPT-4o-miniï¼Œè¿”å›ç»“æœ
![æ™ºèƒ½å›ç­”](https://s2.loli.net/2025/01/20/OTaFQSLXkJ24xum.png)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ’» å®‰è£…æ­¥éª¤

1. å…‹éš†é¡¹ç›®ä»£ç 

```bash
git clone https://github.com/mantoufan/yzhanSimilarKline.git
cd yzhanSimilarKline
```

2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. å®‰è£…ä¾èµ–åŒ…

```bash
pip install -r requirements.txt
```

4. é…ç½®ç¯å¢ƒå˜é‡
   åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º`.env`æ–‡ä»¶ï¼Œæ·»åŠ å¿…è¦çš„é…ç½®ï¼š

```
API_KEY=your_api_key
API_BASE=https://api.openai.com
MODEL=gpt-4o-mini
PROXY_URL=your_proxy_url # å¯é€‰ï¼Œç”¨äºè·å–å…¬å¼€é‡‘èæ•°æ®
```

5. å¯åŠ¨åº”ç”¨

```bash
streamlit run streamlit_app.py
```

### ğŸ•¹ï¸ ä½¿ç”¨è¯´æ˜

1. **è¯åˆ¸æœç´¢**ğŸ”ï¼š

   - åœ¨æœç´¢æ¡†è¾“å…¥è‚¡ç¥¨ä»£ç æˆ–åç§°
   - ç³»ç»Ÿä¼šæ˜¾ç¤ºåŒ¹é…çš„è¯åˆ¸åˆ—è¡¨ï¼ŒåŒ…æ‹¬è‚¡ç¥¨ã€æŒ‡æ•°å’Œ ETF
   - æ”¯æŒæ¨¡ç³Šæœç´¢å’Œæ™ºèƒ½åŒ¹é…

2. **K çº¿åˆ†æ**ğŸ“ˆï¼š

   - ç‚¹å‡»æ„Ÿå…´è¶£çš„è¯åˆ¸æŸ¥çœ‹è¯¦æƒ…
   - æŸ¥çœ‹ K çº¿å›¾å’Œç›¸ä¼¼å½¢æ€åˆ†æ
   - ç ”ç©¶è¶‹åŠ¿é¢„æµ‹å’Œé£é™©åˆ†æç»“æœ

3. **æ™ºèƒ½é—®ç­”**ğŸ’¬ï¼š

   - åœ¨é—®ç­”è¾“å…¥æ¡†è¾“å…¥æ‚¨çš„é—®é¢˜
   - ç³»ç»Ÿä¼šåŸºäºå¸‚åœºæ•°æ®æä¾›ä¸“ä¸šåˆ†æ
   - æ”¯æŒå¤šè½®å¯¹è¯å’Œæ·±åº¦åˆ†æ

4. **æ•°æ®å¯¼å‡º**ğŸ“¥ï¼š
   - æ”¶ç›Šé¢„æµ‹è¡¨å¯ä»¥å¯¼å‡º CSV
   - K çº¿å›¾å¯ä»¥ä¿å­˜ä¸º PNG æ ¼å¼

### âš ï¸ ä½¿ç”¨æç¤º

- å»ºè®®ä½¿ç”¨ Chrome æˆ– Firefox æµè§ˆå™¨è·å¾—æœ€ä½³ä½“éªŒ ğŸ‘Œ
- é¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ç¼“å­˜ç”Ÿæˆ â³
- å›¾è¡¨æ”¯æŒç¼©æ”¾ã€å¹³ç§»ç­‰äº¤äº’æ“ä½œ ğŸ–±ï¸
- æ™ºèƒ½é—®ç­”æ”¯æŒå¤šè½®å¯¹è¯ ğŸ’­

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'background': '#ffffff' }}}%%
graph TD
    %% Node Styles
    classDef default fill:#ffffff,stroke:#666,stroke-width:2px
    classDef inputClass fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef searchClass fill:#fff8e1,stroke:#f57f17,stroke-width:3px
    classDef dataClass fill:#e8f5e9,stroke:#2e7d32,stroke-width:3px
    classDef analysisClass fill:#fce4ec,stroke:#c2185b,stroke-width:3px
    classDef qaClass fill:#e8eaf6,stroke:#3f51b5,stroke-width:3px
    classDef visualClass fill:#fff3e0,stroke:#e65100,stroke-width:3px
    classDef cacheClass fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px

    A[ç”¨æˆ·è¾“å…¥æŸ¥è¯¢]:::inputClass
    B[è¯åˆ¸æœç´¢æ¨¡å—]:::searchClass
    C[å¸‚åœºæ•°æ®è·å–]:::dataClass
    D[æ•°æ®ç¼“å­˜å±‚]:::cacheClass

    %% Technical Analysis
    subgraph TA[æŠ€æœ¯åˆ†æå¼•æ“]
        E[Kçº¿å½¢æ€åˆ†æ]:::analysisClass
        F[ç›¸ä¼¼åº¦è®¡ç®—]:::analysisClass
        G[è¶‹åŠ¿é¢„æµ‹]:::analysisClass
        H[é£é™©åˆ†æ]:::analysisClass
    end

    %% Q&A System
    subgraph QA[æ™ºèƒ½é—®ç­”ç³»ç»Ÿ]
        I[æ–‡æœ¬å—æ„å»º]:::qaClass
        J[å‘é‡åŒ–æ£€ç´¢]:::qaClass
        K[LLMé—®ç­”ç”Ÿæˆ]:::qaClass
    end

    %% Visualization
    subgraph VIZ[æ•°æ®å¯è§†åŒ–]
        L[Kçº¿å›¾è¡¨]:::visualClass
        M[ç›¸ä¼¼åº¦å±•ç¤º]:::visualClass
        N[é¢„æµ‹ç»“æœ]:::visualClass
        O[é£é™©æŒ‡æ ‡]:::visualClass
    end

    %% Connections
    A --> B
    B --> C
    C <--> D
    C --> E
    E --> F
    F --> G
    G --> H
    C --> I
    I --> J
    J --> K
    E & F & G & H --> L & M & N & O
    K --> O

    %% Subgraph Styles
    style TA fill:#ffffff,stroke:#666,stroke-width:3px
    style QA fill:#ffffff,stroke:#666,stroke-width:3px
    style VIZ fill:#ffffff,stroke:#666,stroke-width:3px
```

## ğŸ“¦ æ ¸å¿ƒæŠ€æœ¯å®ç°

### 1. K çº¿å½¢æ€è¯†åˆ«ä¸ç›¸ä¼¼åº¦åŒ¹é…

ç³»ç»Ÿä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°å’Œæ¬§æ°è·ç¦»çš„ç»„åˆæ–¹æ³•æ¥è¯†åˆ«ç›¸ä¼¼ K çº¿å½¢æ€ã€‚é€šè¿‡å¯¹ä»·æ ¼åºåˆ—è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä½¿å¾—ä¸åŒæ—¶æœŸã€ä¸åŒä»·ä½çš„ K çº¿å¯ä»¥è¿›è¡Œæ¯”è¾ƒï¼š

```python
def normalize_window(window):
    """å¯¹ä»·æ ¼åºåˆ—è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†"""
    numeric_window = pd.to_numeric(window, errors='coerce')
    if numeric_window.isna().any():
        return None
    return (numeric_window - numeric_window.iloc[0]) / numeric_window.iloc[0] * 100

def calculate_similarity(window1, window2):
    """è®¡ç®—ä¸¤ä¸ªä»·æ ¼åºåˆ—çš„ç›¸ä¼¼åº¦"""
    if len(window1) != len(window2):
        return 0

    norm1 = normalize_window(window1)
    norm2 = normalize_window(window2)

    if norm1 is None or norm2 is None:
        return 0

    try:
        # è®¡ç®—ç›¸å…³ç³»æ•°ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰
        corr, _ = pearsonr(norm1, norm2)
        # è®¡ç®—æ¬§æ°è·ç¦»å¹¶å½’ä¸€åŒ–
        dist = euclidean(norm1, norm2)
        normalized_dist = 1 / (1 + dist/len(window1))
        # åŠ æƒå¹³å‡å¾—åˆ°æœ€ç»ˆç›¸ä¼¼åº¦
        similarity = (corr + 1)/2 * 0.7 + normalized_dist * 0.3
        return similarity
    except:
        return 0
```

æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹ï¼š

- **æ—¶é—´åºåˆ—å¤„ç†**ğŸ•°ï¸ï¼šä½¿ç”¨ pandas çš„ DatetimeIndex å¤„ç† K çº¿æ•°æ®
- **ç»Ÿè®¡å­¦æ–¹æ³•**ğŸ“Šï¼š
  - çš®å°”é€Šç›¸å…³ç³»æ•°ï¼šè¡¡é‡ä»·æ ¼åºåˆ—çš„èµ°åŠ¿ç›¸å…³æ€§
  - æ¬§æ°è·ç¦»ï¼šè¯„ä¼°ä»·æ ¼åºåˆ—çš„å½¢æ€å·®å¼‚
- **æ•°æ®æ ‡å‡†åŒ–**ğŸšï¸ï¼šåŸºäºé¦–æ—¥ä»·æ ¼çš„ç™¾åˆ†æ¯”å˜åŒ–

### 2. å¸‚åœºæ”¶ç›Šé¢„æµ‹

ç³»ç»Ÿé‡‡ç”¨å¤šç»´åº¦çš„æŠ€æœ¯æ–¹æ³•æ¥åˆ†æå’Œé¢„æµ‹å¸‚åœºæ”¶ç›Šï¼š

```python
def analyze_holding_returns(similar_patterns):
    """
    åˆ†æä¸åŒæŒæœ‰æœŸçš„æ”¶ç›Šæƒ…å†µ

    æŠ€æœ¯è¦ç‚¹ï¼š
    1. æŒä»“æœŸæ”¶ç›Šç‡è®¡ç®—ï¼šè¯„ä¼°ä¸åŒæ—¶é—´å‘¨æœŸçš„æ”¶ç›Šè¡¨ç°
    2. é£é™©åº¦é‡ï¼šä½¿ç”¨æ ‡å‡†å·®/æ³¢åŠ¨ç‡è¯„ä¼°æŠ•èµ„é£é™©
    3. èƒœç‡ç»Ÿè®¡ï¼šåˆ†æä¸åŒæŒæœ‰æœŸçš„ç›ˆåˆ©æ¦‚ç‡
    """
    stats = {str(i): {
        'returns': [],
        'max_prices': [],
        'min_prices': [],
        'win_count': 0,
        'loss_count': 0,
    } for i in range(1, 8)}

    for pattern in similar_patterns:
        entry_price = pattern['pattern_data'].iloc[-1]['close']
        future_data = pattern['future_data']

        for days in range(1, 8):
            day_key = str(days)
            if days <= len(future_data):
                holding_period_data = future_data.iloc[:days]
                exit_price = holding_period_data.iloc[-1]['close']
                returns = (exit_price - entry_price) / entry_price * 100

                stats[day_key]['returns'].append(returns)

                if returns > 0:
                    stats[day_key]['win_count'] += 1
                else:
                    stats[day_key]['loss_count'] += 1

                stats[day_key]['max_prices'].append(
                    holding_period_data['high'].max()
                )
                stats[day_key]['min_prices'].append(
                    holding_period_data['low'].min()
                )

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    analysis_results = {}
    for days, day_stats in stats.items():
        returns_array = np.array(day_stats['returns'])
        total_trades = len(returns_array)

        if total_trades > 0:
            analysis_results[days] = {
                'avg_return': np.mean(returns_array),
                'max_return': np.max(returns_array),
                'min_return': np.min(returns_array),
                'std_return': np.std(returns_array),
                'win_rate': day_stats['win_count'] / total_trades,
                'trade_count': total_trades,
                'max_price_change': (
                    np.max(day_stats['max_prices']) - entry_price
                ) / entry_price * 100,
                'min_price_change': (
                    np.min(day_stats['min_prices']) - entry_price
                ) / entry_price * 100
            }

    return analysis_results

def analyze_future_trends(similar_patterns):
    """
    åŸºäºå†å²Kçº¿åˆ†ææœªæ¥å¯èƒ½çš„èµ°åŠ¿

    æŠ€æœ¯è¦ç‚¹ï¼š
    1. å†å²æ¨¡å¼åŒ¹é…ï¼šåŸºäºç›¸ä¼¼Kçº¿çš„å†å²è¡¨ç°
    2. ç»Ÿè®¡æ¦‚ç‡åˆ†æï¼šè®¡ç®—æ¶¨è·Œæ¦‚ç‡å’Œå¹…åº¦åˆ†å¸ƒ
    3. è¶‹åŠ¿é¢„æµ‹å»ºæ¨¡ï¼šæ„å»ºæœªæ¥å¯èƒ½çš„èµ°åŠ¿é¢„æµ‹
    """
    if not similar_patterns:
        return None

    stats = {
        'up': {str(i): {
            'count': 0, 'max': 0, 'min': float('inf'),
            'mean': 0, 'values': []
        } for i in range(1, 8)},
        'down': {str(i): {
            'count': 0, 'max': 0, 'min': float('inf'),
            'mean': 0, 'values': []
        } for i in range(1, 8)}
    }

    # ç»Ÿè®¡å†å²èµ°åŠ¿æ•°æ®
    for pattern in similar_patterns:
        future_data = pattern['future_data']

        for i in range(len(future_data)):
            day = str(i + 1)
            current_price = future_data.iloc[i]['close']
            prev_price = (
                pattern['pattern_data'].iloc[-1]['close']
                if i == 0
                else future_data.iloc[i-1]['close']
            )

            change_rate = (
                (current_price - prev_price) / prev_price
            ) * 100

            category = 'up' if change_rate >= 0 else 'down'
            change_rate = abs(change_rate)

            stats[category][day]['count'] += 1
            stats[category][day]['values'].append(change_rate)
            stats[category][day]['max'] = max(
                stats[category][day]['max'],
                change_rate
            )
            stats[category][day]['min'] = min(
                stats[category][day]['min'],
                change_rate
            )

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    total_patterns = len(similar_patterns)
    for category in ['up', 'down']:
        for day in stats[category]:
            day_stats = stats[category][day]
            if day_stats['count'] > 0:
                day_stats['probability'] = (
                    day_stats['count'] / total_patterns
                )
                day_stats['mean'] = (
                    sum(day_stats['values']) / day_stats['count']
                )

                # è®¡ç®—ä¼—æ•°(æœ€å¯èƒ½å‡ºç°çš„æ¶¨è·Œå¹…)
                rounded_values = [
                    round(x, 2) for x in day_stats['values']
                ]
                value_counts = {}
                for v in rounded_values:
                    value_counts[v] = value_counts.get(v, 0) + 1
                day_stats['mode'] = max(
                    value_counts.items(),
                    key=lambda x: x[1]
                )[0]

            del day_stats['values']  # æ¸…ç†åŸå§‹æ•°æ®ï¼Œåªä¿ç•™ç»Ÿè®¡ç»“æœ

    return stats
```

æ”¶ç›Šé¢„æµ‹çš„å…³é”®æŠ€æœ¯ç‰¹ç‚¹ï¼š

- **å¤šç»´åº¦åˆ†æ**ï¼š

  - æŒä»“æœŸæ”¶ç›Šç‡è®¡ç®—ï¼šè¯„ä¼°ä¸åŒæ—¶é—´å‘¨æœŸçš„æ”¶ç›Šè¡¨ç°
  - é£é™©åº¦é‡ï¼šä½¿ç”¨æ ‡å‡†å·®è¡¡é‡æ³¢åŠ¨é£é™©
  - æ¦‚ç‡ç»Ÿè®¡ï¼šè®¡ç®—èƒœç‡å’Œæœ€å¯èƒ½å‡ºç°çš„æ¶¨è·Œå¹…
  - è¶‹åŠ¿é¢„æµ‹ï¼šåŸºäºå†å²ç›¸ä¼¼å½¢æ€é¢„æµ‹æœªæ¥èµ°åŠ¿

- **é£é™©è¯„ä¼°æŒ‡æ ‡**ï¼š

  - æ ‡å‡†å·®ï¼šè¡¡é‡æ”¶ç›Šç‡çš„æ³¢åŠ¨æ€§
  - æœ€å¤§å›æ’¤ï¼šè®¡ç®—å¯èƒ½çš„æœ€å¤§æŸå¤±
  - èƒœç‡ï¼šç»Ÿè®¡ç›ˆåˆ©çš„æ¦‚ç‡
  - æ”¶ç›Šåˆ†å¸ƒï¼šåˆ†ææ”¶ç›Šçš„ç¦»æ•£ç¨‹åº¦

- **é¢„æµ‹æ¨¡å‹ç‰¹ç‚¹**ï¼š
  - åŸºäºå†å²ç›¸ä¼¼åº¦çš„æ¨¡å¼è¯†åˆ«
  - æ¦‚ç‡åˆ†å¸ƒçš„ç»Ÿè®¡åˆ†æ
  - å¤šå‘¨æœŸçš„æ”¶ç›Šç‡è®¡ç®—
  - åŠ¨æ€çš„é£é™©æ”¶ç›Šè¯„ä¼°

### 3. æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

ç³»ç»Ÿé‡‡ç”¨ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯æ¶æ„ï¼Œç»“åˆå‘é‡åŒ–æ£€ç´¢å’Œå¤§è¯­è¨€æ¨¡å‹ï¼š

```python
def get_analysis_prompt(query, relevant_chunks, chat_history=None):
    """
    æ„å»ºå¸¦æœ‰æ£€ç´¢ä¸Šä¸‹æ–‡å’Œå¯¹è¯å†å²çš„åˆ†ææç¤º

    æŠ€æœ¯è¦ç‚¹ï¼š
    1. å¯¹è¯å†å²ç®¡ç†ï¼šè¿½è¸ªå¹¶å…³è”å¤šè½®å¯¹è¯ä¿¡æ¯
    2. ä¸Šä¸‹æ–‡æ•´åˆï¼šå°†å†å²å¯¹è¯ä¸å½“å‰é—®é¢˜ç»“åˆ
    3. æç¤ºè¯å·¥ç¨‹ï¼šæ„å»ºç»“æ„åŒ–çš„åˆ†ææŒ‡ä»¤
    """
    # åŸºç¡€å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
    context = "\n".join([chunk for _, chunk in relevant_chunks])

    # æ„å»ºåŸºç¡€æç¤ºè¯
    prompt = f"""ä½œä¸ºä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹ç›¸å…³å¸‚åœºæ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. åªä½¿ç”¨æä¾›çš„æ•°æ®è¿›è¡Œåˆ†æï¼Œä¸è¦æ·»åŠ å…¶ä»–å¸‚åœºä¿¡æ¯
2. æ˜ç¡®åŒºåˆ†æ•°æ®æ”¯æŒçš„ç»“è®ºå’Œä¸ç¡®å®šçš„æ¨æµ‹
3. å¦‚æœæ•°æ®ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
4. é€‚å½“æé†’æŠ•èµ„é£é™©

ç›¸å…³å¸‚åœºæ•°æ®ï¼š
{context}
"""

    # æ•´åˆå¯¹è¯å†å²
    if chat_history and len(chat_history) > 0:
        prompt += "\nå¯¹è¯å†å²ï¼š\n"
        for i, (user_msg, assistant_msg) in enumerate(chat_history, 1):
            prompt += f"ç¬¬{i}è½®é—®ç­”ï¼š\n"
            prompt += f"ç”¨æˆ·ï¼š{user_msg}\n"
            prompt += f"åŠ©æ‰‹ï¼š{assistant_msg}\n"

    # æ·»åŠ å½“å‰é—®é¢˜
    prompt += f"\nå½“å‰ç”¨æˆ·é—®é¢˜ï¼š{query}"

    # æ·»åŠ è§’è‰²æŒ‡ç¤º
    prompt += """

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å’Œå¯¹è¯å†å²ï¼Œéµå¾ªä»¥ä¸‹åŸåˆ™å›ç­”ï¼š
1. ç”¨ä¸“ä¸šä¸”é€šä¿—çš„è¯­è¨€å›ç­”é—®é¢˜ï¼Œç¡®ä¿åˆ†æé€»è¾‘æ¸…æ™°
2. å¦‚æœæ¶‰åŠåˆ°ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œè¯·ä¿æŒåˆ†æçš„è¿è´¯æ€§
3. åœ¨å›ç­”ä¸­é€‚å½“æä¾›ä¸€äº›æ€è€ƒçš„åˆ‡å…¥ç‚¹ï¼Œå¼•å¯¼ç”¨æˆ·è¿›è¡Œæ›´æ·±å…¥çš„æé—®
4. å¦‚æœç”¨æˆ·è¿½é—®æŸä¸ªè§‚ç‚¹ï¼Œè¯·è¿›ä¸€æ­¥å±•å¼€è§£é‡ŠèƒŒåçš„åŸç†å’Œä¾æ®
5. å¦‚æœæŸä¸ªåˆ†ææ¶‰åŠåˆ°å¤šä¸ªæ–¹é¢ï¼Œå¯ä»¥æ˜ç¡®æŒ‡å‡ºï¼Œæ–¹ä¾¿ç”¨æˆ·é€‰æ‹©æ„Ÿå…´è¶£çš„æ–¹å‘ç»§ç»­æ¢è®¨
"""

    return prompt
```

æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹ï¼š

- **RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ**ï¼š

  - æ–‡æœ¬å—æ„å»ºï¼šå°†å¸‚åœºæ•°æ®ç»“æ„åŒ–ä¸ºå¯æ£€ç´¢çš„æ–‡æœ¬å—
  - å‘é‡åŒ–æ£€ç´¢ï¼šä½¿ç”¨ TF-IDF å’Œ SVD è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
  - ç›¸ä¼¼åº¦åŒ¹é…ï¼šåŸºäºä½™å¼¦ç›¸ä¼¼åº¦æŸ¥æ‰¾ç›¸å…³å†…å®¹

- **å¤šè½®å¯¹è¯ç®¡ç†**ï¼š
  - ä¼šè¯çŠ¶æ€ç»´æŠ¤ï¼šä½¿ç”¨ session_state ä¿å­˜å¯¹è¯å†å²
  - ä¸Šä¸‹æ–‡å…³è”ï¼šå°†å†å²å¯¹è¯èå…¥å½“å‰åˆ†æ
  - åŠ¨æ€æç¤ºè¯ï¼šæ ¹æ®å¯¹è¯å†å²è°ƒæ•´å›ç­”ç­–ç•¥

### 4. æ•°æ®å¤„ç†ä¼˜åŒ–

ç³»ç»Ÿå®ç°äº†å¤šé‡ä¼˜åŒ–æœºåˆ¶æ¥æå‡æ•°æ®å¤„ç†æ•ˆç‡ï¼š

```python
@file_cache(cache_dir="./securities_cache", expire_days=30)
def load_security_data(security_type: str) -> pd.DataFrame:
    """åŠ è½½è¯åˆ¸æ•°æ®ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶ç¼“å­˜"""
    try:
        if security_type == 'index':
            return adata.stock.info.all_index_code()
        elif security_type == 'stock':
            return adata.stock.info.all_code()
        elif security_type == 'etf':
            return adata.fund.info.all_etf_exchange_traded_info()
        else:
            return pd.DataFrame()
    except Exception as e:
        print(f"åŠ è½½{security_type}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return pd.DataFrame()

class ChineseTextVectorizer:
    """ä¸­æ–‡æ–‡æœ¬å‘é‡åŒ–å¤„ç†å™¨"""
    def __init__(self, vector_size=100):
        self.tfidf = TfidfVectorizer(
            tokenizer=self._parallel_tokenize,
            max_features=2000
        )
        self.svd = TruncatedSVD(
            n_components=vector_size,
            random_state=42
        )
        self.is_fitted = False
        jieba.initialize()

    def _parallel_tokenize(self, text):
        """å¹¶è¡Œåˆ†è¯å¤„ç†å™¨"""
        if len(text) < 1000:
            return self._tokenize(text)

        chunks = self._split_text(text)
        with ThreadPoolExecutor(max_workers=4) as executor:
            results = list(executor.map(self._tokenize, chunks))
        return [token for chunk_result in results for token in chunk_result]
```

### 5. æ€§èƒ½ä¼˜åŒ–ä¸ç¼“å­˜æœºåˆ¶

ç³»ç»Ÿé‡‡ç”¨å¤šå±‚ç¼“å­˜ç­–ç•¥æå‡æ€§èƒ½ï¼š

```python
def file_cache(cache_dir="./data_cache", expire_days=1):
    """
    æ–‡ä»¶ç¼“å­˜è£…é¥°å™¨

    æŠ€æœ¯ç‰¹ç‚¹ï¼š
    1. æ”¯æŒæ–‡ä»¶ç³»ç»Ÿç¼“å­˜
    2. å¯é…ç½®è¿‡æœŸæ—¶é—´
    3. è‡ªåŠ¨åˆ›å»ºç¼“å­˜ç›®å½•
    4. å¼‚å¸¸å¤„ç†å’Œå®¹é”™æœºåˆ¶
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            # åˆ›å»ºç¼“å­˜ç›®å½•
            os.makedirs(cache_dir, exist_ok=True)

            # æ„å»ºç¼“å­˜æ–‡ä»¶è·¯å¾„
            cache_key = f"{func.__name__}_{str(args)}_{str(kwargs)}"
            cache_file = os.path.join(cache_dir, f"{cache_key}.json")
            meta_file = os.path.join(cache_dir, f"{cache_key}_meta.json")

            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
            if os.path.exists(cache_file) and os.path.exists(meta_file):
                with open(meta_file, 'r') as f:
                    meta = json.load(f)
                cache_time = datetime.strptime(
                    meta['timestamp'],
                    '%Y-%m-%d %H:%M:%S'
                )

                # å¦‚æœç¼“å­˜æœªè¿‡æœŸï¼Œç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
                if datetime.now() - cache_time < timedelta(days=expire_days):
                    with open(cache_file, 'r') as f:
                        return json.load(f)

            # è·å–æ–°æ•°æ®
            results = func(*args, **kwargs)

            # ä¿å­˜åˆ°ç¼“å­˜
            try:
                with open(cache_file, 'w') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)

                meta = {
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'function': func.__name__,
                    'args': str(args),
                    'kwargs': str(kwargs)
                }
                with open(meta_file, 'w') as f:
                    json.dump(meta, f, ensure_ascii=False, indent=2)

            except Exception as e:
                print(f"å†™å…¥ç¼“å­˜æ–‡ä»¶å‡ºé”™: {str(e)}")

            return results
        return wrapper
    return decorator
```

## â­ ç³»ç»Ÿç‰¹ç‚¹

1. **é«˜æ•ˆæ•°æ®å¤„ç†**ğŸš€ï¼š

   - æ–‡ä»¶ç¼“å­˜æœºåˆ¶ï¼Œæé«˜æ•°æ®åŠ è½½é€Ÿåº¦ ğŸ’¾
   - ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæœç´¢ä¸åŒç±»å‹è¯åˆ¸ ğŸ§µ
   - LRU ç¼“å­˜ä¼˜åŒ–åˆ†è¯ç»“æœ â³
   - é•¿æ–‡æœ¬çš„å¹¶è¡Œåˆ†è¯å¤„ç† âš¡

2. **ç²¾å‡†åˆ†æå¼•æ“**ğŸ§®ï¼š

   - åŸºäºçš®å°”é€Šç›¸å…³ç³»æ•°å’Œæ¬§æ°è·ç¦»çš„ K çº¿ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå®ç°äº†ç²¾ç¡®çš„å½¢æ€è¯†åˆ«
   - TF-IDF å’Œ SVD çš„æ–‡æœ¬å‘é‡åŒ–å¤„ç†ï¼Œæä¾›äº†é«˜è´¨é‡çš„è¯­ä¹‰æ£€ç´¢
   - åŸºäºç»Ÿè®¡æ¨¡å‹çš„é£é™©æ”¶ç›Šåˆ†æï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ•°æ®æ”¯æŒ
   - å¤šç»´åº¦çš„è¶‹åŠ¿é¢„æµ‹å’Œé£é™©è¯„ä¼°ï¼Œå¸®åŠ©æŠ•èµ„è€…å…¨é¢äº†è§£å¸‚åœºçŠ¶å†µ

3. **ç”¨æˆ·å‹å¥½ç•Œé¢**ğŸ‘¨â€ğŸ’»ï¼š

   - æ¸…æ™°çš„æ•°æ®å¯è§†åŒ–å±•ç¤ºï¼Œè®©å¤æ‚çš„å¸‚åœºæ•°æ®æ›´æ˜“ç†è§£
   - ç®€æ´çš„æœç´¢åŠŸèƒ½ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…å’Œæ™ºèƒ½æ’åº
   - æ™ºèƒ½çš„é—®ç­”ç³»ç»Ÿï¼Œèƒ½å¤Ÿè¿›è¡Œè‡ªç„¶æµç•…çš„å¤šè½®å¯¹è¯
   - äº¤äº’å¼å›¾è¡¨è®¾è®¡ï¼Œæ”¯æŒç¼©æ”¾ã€å¹³ç§»ç­‰æ“ä½œ
   - ä¸“ä¸šåˆ†æä¸é€šä¿—è§£é‡Šç›¸ç»“åˆï¼Œç…§é¡¾ä¸åŒå±‚æ¬¡ç”¨æˆ·éœ€æ±‚

4. **é«˜æ€§èƒ½æ¶æ„**âš¡ï¼š
   - å¤šå±‚ç¼“å­˜è®¾è®¡ï¼Œæ˜¾è‘—æå‡æ•°æ®è®¿é—®é€Ÿåº¦
   - å¹¶è¡Œå¤„ç†æœºåˆ¶ï¼Œä¼˜åŒ–å¤§è§„æ¨¡æ•°æ®åˆ†ææ€§èƒ½
   - æ¨¡å—åŒ–æ¶æ„ï¼Œä¾¿äºåŠŸèƒ½æ‰©å±•å’Œç»´æŠ¤
   - å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®ä½¿ç”¨å£°æ˜**ğŸ“‹ï¼š

   - ç³»ç»Ÿä½¿ç”¨çš„å¸‚åœºæ•°æ®ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
   - å†å²æ•°æ®åˆ†æç»“æœä¸èƒ½é¢„ç¤ºæœªæ¥å¸‚åœºè¡¨ç°
   - ç”¨æˆ·éœ€è¦è‡ªè¡Œæ‰¿æ‹…æŠ•èµ„å†³ç­–çš„é£é™©
   - å»ºè®®ç»“åˆå…¶ä»–åˆ†æå·¥å…·å’Œä¸“ä¸šæ„è§è¿›è¡ŒæŠ•èµ„å†³ç­–

2. **ç³»ç»Ÿå±€é™æ€§**ğŸ”ï¼š

   - K çº¿å½¢æ€è¯†åˆ«åŸºäºå†å²æ•°æ®ï¼Œå¯èƒ½å­˜åœ¨æ»åæ€§
   - å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å½±å“å†å²æ¨¡å¼çš„æœ‰æ•ˆæ€§
   - æŠ€æœ¯åˆ†æéœ€è¦é…åˆåŸºæœ¬é¢åˆ†æä½¿ç”¨
   - ä¸åŒå¸‚åœºé˜¶æ®µçš„é¢„æµ‹å‡†ç¡®åº¦å¯èƒ½æœ‰æ‰€å·®å¼‚

3. **ä½¿ç”¨å»ºè®®**ğŸ’¡ï¼š
   - å»ºè®®å°†ç³»ç»Ÿä½œä¸ºå†³ç­–å‚è€ƒå·¥å…·ä¹‹ä¸€
   - é‡è§†é£é™©ç®¡ç†ï¼Œä¸è¦è¿‡åˆ†ä¾èµ–å•ä¸€æŒ‡æ ‡
   - å®šæœŸæ£€éªŒå’Œè°ƒæ•´æŠ•èµ„ç­–ç•¥
   - ä¿æŒç†æ€§æ€è€ƒï¼Œé¿å…æƒ…ç»ªåŒ–å†³ç­–

## ğŸ‰ æ€»ç»“ä¸å±•æœ›

åœ¨ A è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿçš„å¼€å‘è¿‡ç¨‹ä¸­ï¼Œæœ¬é¡¹ç›®æˆåŠŸå°†ä¼ ç»ŸæŠ€æœ¯åˆ†æä¸ç°ä»£äººå·¥æ™ºèƒ½æŠ€æœ¯ç›¸ç»“åˆï¼Œä¸»è¦å–å¾—äº†ä»¥ä¸‹æˆæœï¼š

1. **æŠ€æœ¯åˆ›æ–°**ğŸ”¬ï¼š

   - å®ç°äº†åŸºäºçš®å°”é€Šç›¸å…³ç³»æ•°å’Œæ¬§æ°è·ç¦»çš„ K çº¿å½¢æ€è¯†åˆ«
   - æ„å»ºäº†é«˜æ•ˆçš„æ–‡ä»¶ç¼“å­˜ç³»ç»Ÿæå‡æ•°æ®åŠ è½½æ€§èƒ½
   - å¼€å‘äº†åŸºäº TF-IDF å’Œ SVD çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
   - é›†æˆäº†å¸‚åœºæ•°æ®åˆ†æå’Œé£é™©è¯„ä¼°åŠŸèƒ½

2. **å®é™…åº”ç”¨**ğŸ’¼ï¼š

   - ç³»ç»Ÿå¯ä»¥æœ‰æ•ˆè¯†åˆ«å¸‚åœºä¸­çš„ç›¸ä¼¼ K çº¿å½¢æ€
   - æä¾›äº†å®¢è§‚çš„æ”¶ç›Šé£é™©åˆ†ææ•°æ®
   - æ”¯æŒè‡ªç„¶è¯­è¨€çš„å¸‚åœºåˆ†æå¯¹è¯
   - å®ç°äº†ç›´è§‚çš„æ•°æ®å¯è§†åŒ–å±•ç¤º

3. **æœªæ¥æ”¹è¿›æ–¹å‘**ğŸš€ï¼š

   a. æ¥å£æ€§èƒ½ä¼˜åŒ–ï¼š

   - å‡çº§åˆ°æ›´å¿«çš„æ•°æ®æœåŠ¡æä¾›å•†
   - ä¼˜åŒ–æ•°æ®ç¼“å­˜ç­–ç•¥
   - å®ç°å¢é‡æ•°æ®æ›´æ–°æœºåˆ¶
   - æ·»åŠ æ•°æ®é¢„åŠ è½½åŠŸèƒ½

   b. æ¡†æ¶å‡çº§ï¼š

   - è¯„ä¼°æ›´é«˜æ€§èƒ½çš„ Web æ¡†æ¶
   - ä¼˜åŒ–å‰ç«¯æ¸²æŸ“æ€§èƒ½
   - æ”¹è¿›ç”¨æˆ·ç•Œé¢äº¤äº’ä½“éªŒ
   - å¢å¼ºç§»åŠ¨ç«¯é€‚é…èƒ½åŠ›

   c. åˆ†æåŠŸèƒ½å¢å¼ºï¼š

   - å¼•å…¥æ›´å¤šæŠ€æœ¯æŒ‡æ ‡åˆ†æ
   - æ·»åŠ å¸‚åœºæƒ…ç»ªåˆ†æ
   - é›†æˆåŸºæœ¬é¢æ•°æ®åˆ†æ
   - æä¾›æ›´å…¨é¢çš„å¸‚åœºæ´å¯Ÿ

   d. AI æ¨¡å‹ä¼˜åŒ–ï¼š

   - æ¢ç´¢æ›´å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹
   - å¢å¼ºå¤šè½®å¯¹è¯çš„è¿è´¯æ€§
   - æå‡é—®ç­”è´¨é‡å’Œå‡†ç¡®åº¦
   - æ·»åŠ ä¸ªæ€§åŒ–åˆ†ææ¨è

æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªé¡¹ç›®æˆåŠŸå®ç°äº†æŠ€æœ¯åˆ†æä¸äººå·¥æ™ºèƒ½çš„åŸºç¡€ç»“åˆï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›äº†æ•°æ®æ”¯æŒã€‚é€šè¿‡ä¸æ–­ä¼˜åŒ–å’Œå®Œå–„ï¼Œç³»ç»Ÿå°†ç»§ç»­æœç€æ›´ä¸“ä¸šã€æ›´æ™ºèƒ½çš„æ–¹å‘å‘å±•ï¼Œä¸ºæŠ•èµ„è€…æä¾›æ›´æœ‰ä»·å€¼çš„å¸‚åœºåˆ†æå·¥å…·ã€‚æˆ‘ç›¸ä¿¡ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥å’Œå¸‚åœºçš„å‘å±•ï¼Œè¿™ç±»æ™ºèƒ½åˆ†æç³»ç»Ÿå°†åœ¨æŠ•èµ„å†³ç­–ä¸­å‘æŒ¥è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚
