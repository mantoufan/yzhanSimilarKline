# ğŸ“ˆ A è‚¡æ•°æ®æ™ºèƒ½åˆ†æç³»ç»Ÿ

## ğŸ‘¨â€ğŸ’» ä½œè€…ä¿¡æ¯

å§“åï¼šå´å°å®‡
å­¦å·ï¼š71265700016
è¯¾ç¨‹ï¼šå•†ä¸šæ™ºèƒ½æŠ€æœ¯
è€å¸ˆï¼šé˜®å…‰å†Œæ•™æˆ

## ğŸŒŸ ç³»ç»Ÿç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªé¢å‘æŠ•èµ„è€…çš„ A è‚¡å¸‚åœºæ™ºèƒ½åˆ†æç³»ç»Ÿï¼Œæ—¨åœ¨æä¾›å®¢è§‚çš„å¸‚åœºåˆ†æå’ŒæŠ•èµ„å»ºè®®ã€‚ğŸ’¡ å®ƒçš„æ ¸å¿ƒåœ¨äºå°†ä¼ ç»Ÿçš„æŠ€æœ¯åˆ†æå’Œç°ä»£äººå·¥æ™ºèƒ½ç›¸ç»“åˆï¼Œä¸ºå¸‚åœºå†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚

è¿™ä¸ªç³»ç»Ÿæ•´åˆäº†æŠ€æœ¯åˆ†æ ğŸ” å’Œæ™ºèƒ½é—®ç­” ğŸ’¬ åŠŸèƒ½ï¼Œé‡‡ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°å’Œæ¬§æ°è·ç¦»ç­‰ç®—æ³•è¿›è¡Œç›¸ä¼¼ K çº¿å½¢æ€è¯†åˆ«ï¼Œç»“åˆåŸºäºç»Ÿè®¡æ¦‚ç‡çš„ä»·æ ¼èµ°åŠ¿é¢„æµ‹ ğŸ“‰ï¼Œä»¥åŠé€šè¿‡å†å²ç›¸ä¼¼åº¦åŒ¹é…å’Œé£é™©åº¦é‡ï¼ˆæ ‡å‡†å·®/æ³¢åŠ¨ç‡ï¼‰çš„æŒä»“æœŸåˆ†æ ğŸ“Šï¼Œå¹¶åŸºäºå¸‚åœºå®æ—¶æ•°æ®ã€RAG æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œ GPT-4o-mini çš„æ™ºèƒ½é—®ç­”æœåŠ¡ã€‚

ç³»ç»Ÿé‡‡ç”¨ TF-IDF å‘é‡åŒ–ã€SVD é™ç»´ç­‰æœºå™¨å­¦ä¹ ç®—æ³•å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ ğŸ¤–ï¼Œè‡´åŠ›äºé€šè¿‡æ•°æ®é©±åŠ¨çš„æ–¹å¼ä¸ºæŠ•èµ„å†³ç­–æä¾›å‚è€ƒã€‚ç³»ç»Ÿè®¾è®¡çš„ç›®æ ‡æ˜¯å¸®åŠ©æŠ•èµ„è€…æ›´å…¨é¢åœ°äº†è§£å¸‚åœºä¿¡æ¯ï¼Œç†æ€§æƒè¡¡æŠ•èµ„é£é™©ã€‚âš–ï¸

## ğŸ”— æºç åœ°å€

[GitHub ä»“åº“](https://github.com/mantoufan/yzhanSimilarKline)

## ğŸ¥ Demo

> æ¥å£é™é¢‘é™é€Ÿï¼Œæ‚¨å¯ä»¥æœç´¢"**å¹³å®‰**""**ä¸Šè¯æŒ‡æ•°**"æŸ¥çœ‹ã€‚

- å…¶å®ƒå…³é”®è¯éœ€è¦è¯·æ±‚æ¥å£ï¼Œå¤§æ¦‚éœ€è¦ç­‰å¾… 5 åˆ†é’Ÿç”šè‡³æ›´é•¿æ‰æœ‰ç»“æœã€‚âŒ›
- æœ¬åœ°è¿è¡Œé€Ÿåº¦æ›´å¿« ğŸš€

[Demo Link](https://skline.streamlit.app/) | [Video Link](https://drfs.ctcontents.com/file/3312/1449237316/62baf7/yun/business-ai-demo.mp4)  
![ç³»ç»Ÿæ¼”ç¤º GIF](https://github.com/user-attachments/assets/230df622-bc67-4407-94e6-ee16a0c8929c)

## ğŸ™ è‡´è°¢

ç‰¹åˆ«æ„Ÿè°¢é˜®å…‰å†Œæ•™æˆåœ¨å•†ä¸šæ™ºèƒ½æŠ€æœ¯è¯¾ç¨‹ä¸­å¯¹ç›¸å…³æŠ€æœ¯å’Œæ¡ˆä¾‹çš„è®²è§£ï¼Œå—ç›ŠåŒªæµ…ã€‚æ•™æˆçš„æŒ‡å¯¼å¸®åŠ©æˆ‘æ›´æ·±å…¥åœ°ç†è§£äº†å•†ä¸šæ™ºèƒ½æŠ€æœ¯çš„å®é™…åº”ç”¨ï¼Œä¸ºæœ¬é¡¹ç›®çš„å¼€å‘æä¾›äº†å®è´µçš„ç†è®ºä¾æ®å’Œæ€è·¯æ–¹å‘ã€‚ğŸ‘¨â€ğŸ«

## ğŸ“· æˆªå›¾

![image](https://github.com/user-attachments/assets/28283905-e235-4c86-85a8-ecbc865efe7a)  
![image](https://github.com/user-attachments/assets/0e7c1649-389e-4076-a4cb-0fb391ec1ca6)  
![image](https://github.com/user-attachments/assets/e8aa9c41-116d-4299-804d-c7ee03f7f40d)  
![image](https://github.com/user-attachments/assets/3e66f535-6c21-455f-bdee-2996ea706839)  
![image](https://github.com/user-attachments/assets/a2614301-4fbc-4214-b13a-3c5ae18b9618)  
![image](https://github.com/user-attachments/assets/17ad1ee7-4da5-4241-82ff-06a12823dbad)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ’» å®‰è£…æ­¥éª¤

1. å…‹éš†é¡¹ç›®ä»£ç 

   ```bash
   git clone https://github.com/mantoufan/yzhanSimilarKline.git
   cd yzhanSimilarKline
   ```

2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

   ```bash
   python -m venv venv
   # Windows
   venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   ```

3. å®‰è£…ä¾èµ–åŒ…

   ```bash
   pip install -r requirements.txt
   ```

4. é…ç½®ç¯å¢ƒå˜é‡
   åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º`.env`æ–‡ä»¶ï¼Œæ·»åŠ å¿…è¦çš„é…ç½®ï¼š

   ```
   API_KEY=your_api_key
   API_BASE=https://api.openai.com
   MODEL=gpt-4o-mini
   PROXY_URL=your_proxy_url # å¯é€‰ï¼Œç”¨äºè·å–å…¬å¼€é‡‘èæ•°æ®
   ```

5. å¯åŠ¨åº”ç”¨
   ```bash
   streamlit run streamlit_app.py
   ```

### ğŸ•¹ï¸ ä½¿ç”¨è¯´æ˜

1. **è¯åˆ¸æœç´¢**ğŸ”ï¼š

   - åœ¨æœç´¢æ¡†è¾“å…¥è‚¡ç¥¨ä»£ç æˆ–åç§°
   - ç³»ç»Ÿä¼šæ˜¾ç¤ºåŒ¹é…çš„è¯åˆ¸åˆ—è¡¨ï¼ŒåŒ…æ‹¬è‚¡ç¥¨ã€æŒ‡æ•°å’Œ ETF
   - æ”¯æŒæ¨¡ç³Šæœç´¢å’Œæ™ºèƒ½åŒ¹é…

2. **K çº¿åˆ†æ**ğŸ“ˆï¼š

   - ç‚¹å‡»æ„Ÿå…´è¶£çš„è¯åˆ¸æŸ¥çœ‹è¯¦æƒ…
   - æŸ¥çœ‹ K çº¿å›¾å’Œç›¸ä¼¼å½¢æ€åˆ†æ
   - ç ”ç©¶è¶‹åŠ¿é¢„æµ‹å’Œé£é™©åˆ†æç»“æœ

3. **æ™ºèƒ½é—®ç­”**ğŸ’¬ï¼š

   - åœ¨é—®ç­”è¾“å…¥æ¡†è¾“å…¥æ‚¨çš„é—®é¢˜
   - ç³»ç»Ÿä¼šåŸºäºå¸‚åœºæ•°æ®æä¾›ä¸“ä¸šåˆ†æ
   - æ”¯æŒå¤šè½®å¯¹è¯å’Œæ·±åº¦åˆ†æ

4. **æ•°æ®å¯¼å‡º**ğŸ“¥ï¼š
   - æ”¶ç›Šé¢„æµ‹è¡¨å¯ä»¥å¯¼å‡º CSV
   - K çº¿å›¾å¯ä»¥ä¿å­˜ä¸º PNG æ ¼å¼

### âš ï¸ ä½¿ç”¨æç¤º

- å»ºè®®ä½¿ç”¨ Chrome æˆ– Firefox æµè§ˆå™¨è·å¾—æœ€ä½³ä½“éªŒ ğŸ‘Œ
- é¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ç¼“å­˜ç”Ÿæˆ â³
- å›¾è¡¨æ”¯æŒç¼©æ”¾ã€å¹³ç§»ç­‰äº¤äº’æ“ä½œ ğŸ–±ï¸
- æ™ºèƒ½é—®ç­”æ”¯æŒå¤šè½®å¯¹è¯ ğŸ’­

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[è¯åˆ¸æœç´¢]
    B --> C[å¸‚åœºæ•°æ®è·å–]
    C --> D[Kçº¿å½¢æ€åˆ†æ]
    C --> E[æ™ºèƒ½é—®ç­”ç³»ç»Ÿ]

    D --> D1[ç›¸ä¼¼Kçº¿è¯†åˆ«]
    D --> D2[è¶‹åŠ¿é¢„æµ‹]
    D --> D3[é£é™©åˆ†æ]

    E --> E1[æ–‡æœ¬å—æ„å»º]
    E --> E2[å‘é‡åŒ–æ£€ç´¢]
    E --> E3[LLMé—®ç­”]

    D1 & D2 & D3 --> F[å¯è§†åŒ–å±•ç¤º]
    E1 & E2 & E3 --> G[åˆ†æç»“æœ]

    F & G --> H[ç”¨æˆ·ç•Œé¢]
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. K çº¿å½¢æ€è¯†åˆ«ä¸ç›¸ä¼¼åº¦åŒ¹é…

ç³»ç»Ÿé‡‡ç”¨æ»‘åŠ¨çª—å£æ–¹æ³•ç»“åˆå¤šç»´ç›¸ä¼¼åº¦è®¡ç®—ï¼Œè¯†åˆ«å’ŒåŒ¹é…å†å² K çº¿å½¢æ€ã€‚é€šè¿‡å¯¹ä»·æ ¼åºåˆ—è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†å’Œç›¸ä¼¼åº¦è®¡ç®—ï¼Œæ‰¾å‡ºæœ€å…·å‚è€ƒä»·å€¼çš„å†å²æ¡ˆä¾‹ï¼š

```python
def normalize_window(window):
    """
    å¯¹ä»·æ ¼åºåˆ—è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†

    ç®—æ³•åŸç†ï¼š
    1. å°†ä»·æ ¼åºåˆ—è½¬æ¢ä¸ºåŒä¸€åŸºå‡†
    2. è®¡ç®—ä»·æ ¼å˜åŒ–çš„ç™¾åˆ†æ¯”
    3. ä½¿å¾—ä¸åŒæ—¶æœŸã€ä¸åŒä»·ä½çš„Kçº¿å¯ä»¥è¿›è¡Œæ¯”è¾ƒ

    è¾“å…¥ï¼š
    - window: pandas.Seriesï¼ŒåŒ…å«æ”¶ç›˜ä»·æ•°æ®

    è¿”å›ï¼š
    - æ ‡å‡†åŒ–åçš„ä»·æ ¼åºåˆ—
    """
    numeric_window = pd.to_numeric(window, errors='coerce')
    if numeric_window.isna().any():
        return None
    # ç›¸å¯¹äºèµ·å§‹ä»·æ ¼çš„å˜åŒ–ç™¾åˆ†æ¯”
    return (numeric_window - numeric_window.iloc[0]) / numeric_window.iloc[0] * 100

def calculate_similarity(window1, window2):
    """
    è®¡ç®—ä¸¤ä¸ªä»·æ ¼åºåˆ—çš„ç›¸ä¼¼åº¦

    è®¡ç®—æ–¹æ³•ï¼š
    1. çš®å°”é€Šç›¸å…³ç³»æ•°ï¼šè¡¡é‡èµ°åŠ¿ç›¸å…³æ€§ï¼ˆæƒé‡0.7ï¼‰
    2. æ¬§æ°è·ç¦»ï¼šè¡¡é‡å½¢æ€å·®å¼‚ï¼ˆæƒé‡0.3ï¼‰

    æŠ€æœ¯ç»†èŠ‚ï¼š
    - ä½¿ç”¨scipy.stats.pearsonrè®¡ç®—ç›¸å…³ç³»æ•°
    - ä½¿ç”¨scipy.spatial.distance.euclideanè®¡ç®—æ¬§æ°è·ç¦»
    - é€šè¿‡åŠ æƒå¹³å‡ç»¼åˆä¸¤ä¸ªæŒ‡æ ‡

    æ”¹è¿›æ›´æ–°ï¼š
    - æ·»åŠ æ•°æ®æœ‰æ•ˆæ€§éªŒè¯
    - ä¼˜åŒ–ç›¸ä¼¼åº¦è®¡ç®—é€»è¾‘
    - å¢åŠ å¼‚å¸¸å¤„ç†æœºåˆ¶

    è¾“å…¥ï¼š
    - window1, window2: ä¸¤ä¸ªä»·æ ¼åºåˆ—

    è¿”å›ï¼š
    - float: ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ä¹‹é—´ï¼‰
    """
    if len(window1) != len(window2):
        return 0

    # æ ‡å‡†åŒ–å¤„ç†
    norm1 = normalize_window(window1)
    norm2 = normalize_window(window2)
    if norm1 is None or norm2 is None:
        return 0

    try:
        # è®¡ç®—ç›¸å…³ç³»æ•°ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰
        corr, _ = pearsonr(norm1, norm2)
        # è®¡ç®—æ¬§æ°è·ç¦»å¹¶å½’ä¸€åŒ–
        dist = euclidean(norm1, norm2)
        normalized_dist = 1 / (1 + dist/len(window1))
        # åŠ æƒå¹³å‡å¾—åˆ°æœ€ç»ˆç›¸ä¼¼åº¦
        similarity = (corr + 1)/2 * 0.7 + normalized_dist * 0.3
        return similarity
    except:
        return 0
```

åº”ç”¨çš„æ ¸å¿ƒæŠ€æœ¯ï¼š

- **æ—¶é—´åºåˆ—å¤„ç†**ğŸ•°ï¸ï¼šä½¿ç”¨ pandas çš„ DatetimeIndex å’Œæ—¶é—´åºåˆ—åˆ‡ç‰‡åŠŸèƒ½å¤„ç† K çº¿æ•°æ®
- **ç»Ÿè®¡å­¦æ–¹æ³•**ğŸ“Šï¼š
  - çš®å°”é€Šç›¸å…³ç³»æ•°ï¼ˆscipy.stats.pearsonrï¼‰ï¼šè¡¡é‡ä»·æ ¼åºåˆ—çš„èµ°åŠ¿ç›¸å…³æ€§
  - æ¬§æ°è·ç¦»ï¼ˆscipy.spatial.distance.euclideanï¼‰ï¼šè¯„ä¼°ä»·æ ¼åºåˆ—çš„å½¢æ€å·®å¼‚
- **æ•°æ®æ ‡å‡†åŒ–**ğŸšï¸ï¼šä½¿ç”¨åŸºäºé¦–æ—¥ä»·æ ¼çš„ç™¾åˆ†æ¯”å˜åŒ–è¿›è¡Œåºåˆ—æ ‡å‡†åŒ–
- **åŠ æƒè¯„åˆ†ç³»ç»Ÿ**âš–ï¸ï¼šç»¼åˆç›¸å…³ç³»æ•°ï¼ˆæƒé‡ 0.7ï¼‰å’Œè·ç¦»æŒ‡æ ‡ï¼ˆæƒé‡ 0.3ï¼‰è®¡ç®—æœ€ç»ˆç›¸ä¼¼åº¦

### 2. æ™ºèƒ½é—®ç­”ç³»ç»Ÿå¢å¼º

ç³»ç»Ÿé‡‡ç”¨æœ€æ–°çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯æ¶æ„ï¼Œé€šè¿‡å‘é‡åŒ–æ£€ç´¢å’Œå¤§è¯­è¨€æ¨¡å‹çš„ç»„åˆï¼Œå®ç°åŸºäºå¸‚åœºæ•°æ®çš„æ™ºèƒ½é—®ç­”ï¼š

```python
def create_text_chunks(security, current_df, similar_patterns, holding_stats):
    """
    æ„å»ºç»“æ„åŒ–æ–‡æœ¬å—ä¾›æ£€ç´¢ï¼ˆ2024æ›´æ–°ç‰ˆï¼‰

    å®ç°åŸç†ï¼š
    1. å°†ä¸åŒç±»å‹çš„å¸‚åœºæ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–æ–‡æœ¬
    2. å¯¹æ–‡æœ¬è¿›è¡Œåˆ†å—ï¼Œä¾¿äºåç»­æ£€ç´¢
    3. æ¯ä¸ªæ–‡æœ¬å—åŒ…å«ç‰¹å®šä¸»é¢˜çš„å®Œæ•´ä¿¡æ¯
    4. æ–°å¢é£é™©åˆ†æå’ŒæŠ€æœ¯æŒ‡æ ‡ç»´åº¦

    æ–‡æœ¬å—ç±»å‹ï¼š
    - è¯åˆ¸åŸºæœ¬ä¿¡æ¯
    - æœ€æ–°è¡Œæƒ…æ•°æ®
    - å†å²è¡¨ç°åˆ†æ
    - ç›¸ä¼¼Kçº¿åˆ†æ
    - æŒä»“æ”¶ç›Šåˆ†æ
    - æŠ€æœ¯æŒ‡æ ‡åˆ†æï¼ˆæ–°å¢ï¼‰
    - é£é™©è¯„ä¼°æŠ¥å‘Šï¼ˆæ–°å¢ï¼‰

    å‚æ•°ï¼š
    - security: dictï¼Œè¯åˆ¸åŸºæœ¬ä¿¡æ¯
    - current_df: DataFrameï¼Œå½“å‰å¸‚åœºæ•°æ®
    - similar_patterns: listï¼Œç›¸ä¼¼Kçº¿åˆ†æç»“æœ
    - holding_stats: dictï¼ŒæŒä»“åˆ†ææ•°æ®

    è¿”å›ï¼š
    - listï¼š(chunk_id, chunk_text) å…ƒç»„åˆ—è¡¨
    """
    chunks = []

    # æ„å»ºåŸºæœ¬ä¿¡æ¯æ–‡æœ¬å—
    basic_info = f"""
        è¯åˆ¸åŸºæœ¬ä¿¡æ¯ï¼š
        åç§°ï¼š{security['name']}
        ä»£ç ï¼š{security['code']}
        ç±»å‹ï¼š{security['type']}
        äº¤æ˜“æ‰€ï¼š{security['exchange']}
    """
    chunks.append(("basic_info", basic_info))

    if current_df is not None and not current_df.empty:
        # æ·»åŠ æœ€æ–°è¡Œæƒ…ä¿¡æ¯
        latest_data = current_df.iloc[-1]
        latest_market = f"""
        æœ€æ–°å¸‚åœºè¡Œæƒ…ï¼ˆ{latest_data['trade_date'].strftime('%Y-%m-%d')}ï¼‰ï¼š
        æ”¶ç›˜ä»·ï¼š{latest_data['close']:.2f}
        å¼€ç›˜ä»·ï¼š{latest_data['open']:.2f}
        æœ€é«˜ä»·ï¼š{latest_data['high']:.2f}
        æœ€ä½ä»·ï¼š{latest_data['low']:.2f}
        æˆäº¤é‡ï¼š{latest_data.get('volume', 'æœªçŸ¥')}
        """
        chunks.append(("latest_market", latest_market))

        # æ·»åŠ å…¶ä»–åˆ†æç»´åº¦...

    return chunks

class ChineseTextVectorizer:
    """
    ä¸­æ–‡æ–‡æœ¬å‘é‡åŒ–å¤„ç†å™¨ï¼ˆ2024ä¼˜åŒ–ç‰ˆï¼‰

    æŠ€æœ¯å®ç°ï¼š
    1. ç»“åˆjiebaåˆ†è¯å’ŒTF-IDFè¿›è¡Œæ–‡æœ¬ç‰¹å¾æå–
    2. ä½¿ç”¨SVDè¿›è¡Œé™ç»´ï¼Œè·å¾—ç¨ å¯†å‘é‡è¡¨ç¤º
    3. å¯¹å‘é‡è¿›è¡Œå½’ä¸€åŒ–ï¼Œæé«˜ç›¸ä¼¼åº¦è®¡ç®—çš„å‡†ç¡®æ€§
    4. æ–°å¢ç¼“å­˜æœºåˆ¶ï¼Œæå‡å¤„ç†æ•ˆç‡

    ä¸»è¦ç»„ä»¶ï¼š
    - jiebaï¼šä¸­æ–‡åˆ†è¯
    - TfidfVectorizerï¼šæ–‡æœ¬ç‰¹å¾æå–
    - TruncatedSVDï¼šé™ç»´å¤„ç†
    - LRUç¼“å­˜ï¼šä¼˜åŒ–æ€§èƒ½
    """
    def __init__(self, vector_size=100):
        # TF-IDFå‘é‡åŒ–å™¨é…ç½®
        self.tfidf = TfidfVectorizer(
            tokenizer=self._tokenize,  # ä½¿ç”¨è‡ªå®šä¹‰åˆ†è¯å™¨
            max_features=2000,  # é™åˆ¶ç‰¹å¾æ•°é‡
            token_pattern=None  # ç¦ç”¨é»˜è®¤çš„tokenæ¨¡å¼
        )
        # SVDé™ç»´é…ç½®
        self.svd = TruncatedSVD(
            n_components=vector_size,  # ç›®æ ‡ç»´åº¦
            random_state=42  # ä¿è¯ç»“æœå¯é‡ç°
        )
        self.is_fitted = False

        # é¢„åŠ è½½ç»“å·´è¯å…¸
        jieba.initialize()

    @lru_cache(maxsize=1000)  # ç¼“å­˜åˆ†è¯ç»“æœ
    def _tokenize(self, text):
        """
        ä¸­æ–‡åˆ†è¯å¤„ç†

        æ­¥éª¤ï¼š
        1. æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        2. ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯
        3. è¿‡æ»¤ç©ºç™½è¯
        4. ç¼“å­˜å¤„ç†ç»“æœ
        """
        text = re.sub(r'[^\w\s]', '', text)
        words = jieba.lcut(text)
        return [w for w in words if w.strip()]
```

### 3. æ•°æ®å¤„ç†ä¼˜åŒ–

æ–°å¢é«˜æ•ˆçš„æ•°æ®ç¼“å­˜å’Œå¤šçº¿ç¨‹å¤„ç†æœºåˆ¶ï¼š

````python
@file_cache(cache_dir="./securities_cache", expire_days=30)
def load_security_data(security_type: str) -> pd.DataFrame:
    """
    åŠ è½½è¯åˆ¸æ•°æ®ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶ç¼“å­˜

    å‚æ•°ï¼š
        security_type: è¯åˆ¸ç±»å‹ ('index', 'stock', 'etf')

    è¿”å›ï¼š
        pd.DataFrame: åŒ…å«è¯åˆ¸ä¿¡æ¯çš„æ•°æ®æ¡†
    """
    try:
        if security_type == 'index':
            return adata.stock.info.all_index_code()
        elif security_type == 'stock':
            return adata.stock.info.all_code()
        elif security_type == 'etf':
            return adata.fund.info.all_etf_exchange_traded_info()
        else:
            return pd.DataFrame()
    except Exception as e:
        print(f"åŠ è½½{security_type}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return pd.DataFrame()

def search_securities(query: str) -> List[Dict]:
    """
    æœç´¢è¯åˆ¸(æŒ‡æ•°ã€è‚¡ç¥¨)ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†

    æŠ€æœ¯ç‰¹ç‚¹:
    1. ä½¿ç”¨LRUç¼“å­˜ä¼˜åŒ–æ•°æ®åŠ è½½
    2. å¤šçº¿ç¨‹å¹¶è¡Œæœç´¢æå‡æ€§èƒ½
    3. å…³é”®è¯é¢„å¤„ç†æé«˜åŒ¹é…å‡†ç¡®æ€§
    4. å¼‚å¸¸å¤„ç†ç¡®ä¿åŠŸèƒ½ç¨³å®šæ€§
    5. ç±»å‹æ³¨è§£å¢å¼ºä»£ç å¯è¯»æ€§

    Args:
        query: æœç´¢å…³é”®è¯(ä»£ç æˆ–åç§°)

    Returns:
        List[Dict]: æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å«:
            - code: è¯åˆ¸ä»£ç 
            - name: è¯åˆ¸åç§°
            - type: è¯åˆ¸ç±»å‹
            - exchange: äº¤æ˜“æ‰€
    """
    if not query or len(query.strip()) == 0:
        return []

    # é¢„å¤„ç†æŸ¥è¯¢å…³é”®è¯
    query = preprocess_query(query)

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæœç´¢ä¸åŒç±»å‹çš„è¯åˆ¸
    security_types = ['index', 'stock', 'etf']
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(search_single_type, query, security_type)
            for security_type in security_types
        ]

        # æ”¶é›†æ‰€æœ‰ç»“æœ
        all_results = []
        for future in futures:
            try:
                results = future.result()
                all_results.extend(results)
            except Exception as e:
                print(f"è·å–æœç´¢ç»“æœæ—¶å‡ºé”™: {str(e)}")

    # æŒ‰ç›¸å…³åº¦æ’åºç»“æœ
    all_results.sort(key=lambda x: (
        -int(x['code'].lower() == query),  # å®Œå…¨åŒ¹é…ä»£ç çš„ä¼˜å…ˆçº§æœ€é«˜
        -int(query in x['code'].lower()),  # å…¶æ¬¡æ˜¯åŒ…å«ä»£ç çš„
        -int(query in x['name'].lower()),  # å†æ¬¡æ˜¯åŒ…å«åç§°çš„
        len(x['code'])  # æœ€åæŒ‰ä»£ç é•¿åº¦æ’åº
    ))

    return all_results

### 4. æ€§èƒ½ä¼˜åŒ–ä¸ç¼“å­˜æœºåˆ¶

ç³»ç»Ÿå¼•å…¥äº†å¤šå±‚ç¼“å­˜æœºåˆ¶å’Œæ€§èƒ½ä¼˜åŒ–æªæ–½ï¼š

```python
def file_cache(cache_dir="./data_cache", expire_days=1):
    """
    æ–‡ä»¶ç¼“å­˜è£…é¥°å™¨ï¼Œå°†æ•°æ®å­˜å‚¨åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ

    æŠ€æœ¯ç‰¹ç‚¹ï¼š
    1. æ”¯æŒè‡ªå®šä¹‰ç¼“å­˜ç›®å½•å’Œè¿‡æœŸæ—¶é—´
    2. ä½¿ç”¨JSONæ ¼å¼å­˜å‚¨æ•°æ®
    3. è‡ªåŠ¨å¤„ç†ç¼“å­˜è¿‡æœŸ
    4. å¼‚å¸¸å¤„ç†æœºåˆ¶ç¡®ä¿ç¨³å®šæ€§

    å‚æ•°ï¼š
        cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
        expire_days: ç¼“å­˜è¿‡æœŸå¤©æ•°ï¼Œé»˜è®¤1å¤©
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            # åˆ›å»ºç¼“å­˜ç›®å½•
            os.makedirs(cache_dir, exist_ok=True)

            # æ„å»ºç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨å‡½æ•°åå’Œå‚æ•°ä½œä¸ºç¼“å­˜é”®
            cache_key = f"{func.__name__}_{str(args)}_{str(kwargs)}"
            cache_file = os.path.join(cache_dir, f"{cache_key}.json")
            meta_file = os.path.join(cache_dir, f"{cache_key}_meta.json")

            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
            if os.path.exists(cache_file) and os.path.exists(meta_file):
                with open(meta_file, 'r') as f:
                    meta = json.load(f)
                cache_time = datetime.strptime(meta['timestamp'],
                                             '%Y-%m-%d %H:%M:%S')

                # å¦‚æœç¼“å­˜æœªè¿‡æœŸï¼Œç›´æ¥ä»æ–‡ä»¶åŠ è½½æ•°æ®
                if datetime.now() - cache_time < timedelta(days=expire_days):
                    try:
                        with open(cache_file, 'r') as f:
                            return json.load(f)
                    except Exception as e:
                        print(f"è¯»å–ç¼“å­˜æ–‡ä»¶å‡ºé”™: {str(e)}")

            # å¦‚æœç¼“å­˜ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸï¼Œé‡æ–°è·å–æ•°æ®
            results = func(*args, **kwargs)

            # ä¿å­˜æ•°æ®åˆ°ç¼“å­˜æ–‡ä»¶
            try:
                # ä¿å­˜æ•°æ®
                with open(cache_file, 'w') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)

                # ä¿å­˜å…ƒæ•°æ®
                meta = {
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'function': func.__name__,
                    'args': str(args),
                    'kwargs': str(kwargs)
                }
                with open(meta_file, 'w') as f:
                    json.dump(meta, f, ensure_ascii=False, indent=2)

            except Exception as e:
                print(f"å†™å…¥ç¼“å­˜æ–‡ä»¶å‡ºé”™: {str(e)}")

            return results
        return wrapper
    return decorator
````

åº”ç”¨çš„æ ¸å¿ƒæŠ€æœ¯ï¼š

1. **å¤šå±‚ç¼“å­˜æœºåˆ¶**ï¼š

   - LRU ç¼“å­˜ï¼šä½¿ç”¨`@lru_cache`è£…é¥°å™¨ç¼“å­˜é¢‘ç¹è®¿é—®çš„æ•°æ®
   - æ–‡ä»¶ç¼“å­˜ï¼šé€šè¿‡`@file_cache`å®ç°æ•°æ®æŒä¹…åŒ–å­˜å‚¨
   - å‘é‡åŒ–ç¼“å­˜ï¼šä¼˜åŒ–æ–‡æœ¬å¤„ç†æ€§èƒ½

2. **å¹¶è¡Œå¤„ç†ä¼˜åŒ–**ï¼š

   - å¤šçº¿ç¨‹æœç´¢ï¼šå¹¶è¡Œå¤„ç†ä¸åŒç±»å‹çš„è¯åˆ¸æœç´¢
   - å¼‚æ­¥æ•°æ®åŠ è½½ï¼šæé«˜å“åº”é€Ÿåº¦
   - çº¿ç¨‹æ± ç®¡ç†ï¼šä¼˜åŒ–èµ„æºä½¿ç”¨

3. **æ•°æ®é¢„å¤„ç†æ”¹è¿›**ï¼š
   - è¯åˆ¸ä»£ç æ ‡å‡†åŒ–
   - ä¸­æ–‡åˆ†è¯ä¼˜åŒ–
   - å¼‚å¸¸æ•°æ®å¤„ç†
   - æ•°æ®éªŒè¯åŠ å¼º

## ğŸ“¦ æŠ€æœ¯æ ˆæ›´æ–°

### æ ¸å¿ƒæ¡†æ¶ä¸åº“

- Streamlitï¼šWeb åº”ç”¨æ¡†æ¶ ğŸŒ
- Plotlyï¼šäº¤äº’å¼æ•°æ®å¯è§†åŒ– ğŸ“Š
- scikit-learnï¼šæœºå™¨å­¦ä¹ ç®—æ³•åº“ ğŸ¤–
- pandas & numpyï¼šæ•°æ®å¤„ç†ä¸ç§‘å­¦è®¡ç®— ğŸ§®
- jiebaï¼šä¸­æ–‡åˆ†è¯å¤„ç† ğŸ€„
- ThreadPoolExecutorï¼šå¤šçº¿ç¨‹å¤„ç† ğŸ§µ
- LRU Cacheï¼šå†…å­˜ç¼“å­˜ä¼˜åŒ– ğŸ’¾

### æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜æœºåˆ¶**ğŸ’¾ï¼š
   - å†…å­˜ç¼“å­˜ï¼š`@lru_cache`è£…é¥°å™¨
   - æ–‡ä»¶ç¼“å­˜ï¼š`@file_cache`è£…é¥°å™¨
   - ç¼“å­˜è¿‡æœŸç®¡ç† â°
   - å¼‚å¸¸å¤„ç†æœºåˆ¶ ğŸš¨
2. **å¹¶è¡Œå¤„ç†**ğŸš€ï¼š

   - å¤šçº¿ç¨‹æœç´¢ ğŸ”
   - å¼‚æ­¥æ•°æ®åŠ è½½ â³
   - èµ„æºæ± ç®¡ç† ğŸŠâ€â™‚ï¸
   - ä»»åŠ¡è°ƒåº¦ä¼˜åŒ– ğŸ—“ï¸

3. **æ•°æ®å¤„ç†**ğŸ§¹ï¼š
   - æ‰¹é‡æ•°æ®å¤„ç† ğŸ“¦
   - å‘é‡åŒ–è¿ç®— ğŸ§®
   - å†…å­˜ä¼˜åŒ– ğŸ’¾
   - é”™è¯¯å¤„ç†å®Œå–„ ğŸ”§

### AI æ¨¡å‹ä¼˜åŒ–

1. **RAG æŠ€æœ¯å¢å¼º**ğŸ§ ï¼š

   - æ”¹è¿›æ–‡æœ¬å—æ„å»º ğŸ“
   - ä¼˜åŒ–å‘é‡æ£€ç´¢ ğŸ”
   - å¢å¼ºç›¸ä¼¼åº¦è®¡ç®— ğŸ“
   - å®Œå–„æç¤ºå·¥ç¨‹ ğŸ’¡

2. **NLP å¤„ç†ä¼˜åŒ–**ğŸ—£ï¸ï¼š
   - åˆ†è¯æ€§èƒ½æå‡ ğŸš„
   - å‘é‡åŒ–æ•ˆç‡ä¼˜åŒ– âš¡
   - ç›¸ä¼¼åº¦ç®—æ³•æ”¹è¿› ğŸ§®
   - ç»“æœæ’åºä¼˜åŒ– ğŸ†

## â­ ç³»ç»Ÿç‰¹ç‚¹

1. **é«˜æ€§èƒ½æ•°æ®å¤„ç†**ğŸš€ï¼š
   - å¤šçº§ç¼“å­˜æœºåˆ¶ ğŸ’¾
   - å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† ğŸ§µ
   - å¼‚æ­¥æ•°æ®åŠ è½½ â³
   - æ€§èƒ½ç›‘æ§ä¼˜åŒ– ğŸ“ˆ
2. **æ™ºèƒ½åˆ†æå¢å¼º**ğŸ§ ï¼š

   - æ”¹è¿›ç›¸ä¼¼åº¦ç®—æ³• ğŸ§®
   - ä¼˜åŒ–æ–‡æœ¬æ£€ç´¢ç²¾åº¦ ğŸ¯
   - å®Œå–„é£é™©åˆ†ææ¨¡å‹ âš ï¸
   - å¢å¼ºé¢„æµ‹å‡†ç¡®æ€§ ğŸ“‰

3. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**ğŸ‘¨â€ğŸ’»ï¼š
   - å“åº”é€Ÿåº¦æå‡ âš¡
   - åˆ†æç»“æœæ›´ä¸“ä¸š ğŸ“Š
   - å±•ç¤ºæ•ˆæœæ›´ç›´è§‚ ğŸ“ˆ
   - æ“ä½œæ›´åŠ ä¾¿æ· ğŸ–±ï¸

## âš ï¸ æ³¨æ„äº‹é¡¹

1. æ‰€æœ‰åˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®® âŒ
2. è¿‡å¾€è¡¨ç°ä¸ä»£è¡¨æœªæ¥æ”¶ç›Š ğŸ“‰
3. æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ… âš ï¸
